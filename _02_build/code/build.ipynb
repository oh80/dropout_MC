{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "43756c26",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import ast\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "d1788248",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_raw_data(path):\n",
    "    raw_df = pd.read_csv(path)\n",
    "    return raw_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "57878cc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preoprocess_data(raw_df):\n",
    "    # extract necessary columns\n",
    "    use_columns = ['ID', '緯度(度)', '緯度(分)', '経度(度)', '経度(分)', 'temp', '観測所名']\n",
    "    df = raw_df[use_columns].copy()  \n",
    "\n",
    "    # rename columuns\n",
    "    df.columns = ['ID', 'latitude_D','latitude_m', 'longitude_D','longitude_m', 'temp', 'station_name']\n",
    "    df[\"latitude\"] = df[\"latitude_D\"] + df[\"latitude_m\"] / 60\n",
    "    df[\"longitude\"] = df[\"longitude_D\"] + df[\"longitude_m\"] / 60\n",
    "\n",
    "    # drop Nan in temp col\n",
    "    df = df[df[\"temp\"].notna()]\n",
    "\n",
    "    # extract only temp values\n",
    "    df[\"temp\"] = df['temp'].apply(lambda x: ast.literal_eval(x)[0])\n",
    "\n",
    "    # # groupby\n",
    "    summarized_df = df.groupby(['latitude', 'longitude', 'station_name']).agg({'temp': 'max'}).reset_index()\n",
    "    return summarized_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "2bc6ffa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(df, test_size=0.2, random_state=42):\n",
    "    train_df, test_df = train_test_split(df, test_size=test_size, random_state=random_state)\n",
    "    return train_df, test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "6cfc0563",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_dataset():\n",
    "    path = \"C://dropout_MC//dropout_MC//_01_data//data//amedas_data_20250713.csv\"\n",
    "    raw_df = read_raw_data(path)\n",
    "\n",
    "    # preprocess\n",
    "    summarized_df = preoprocess_data(raw_df)\n",
    "\n",
    "    # split dataset\n",
    "    train_df, test_df = split_data(summarized_df, test_size=0.3, random_state=42)\n",
    "    \n",
    "    # save\n",
    "    build_dir = os.path.abspath(os.path.join(os.getcwd(), os.pardir))\n",
    "\n",
    "    all_data_path = os.path.join(build_dir, \"data\", \"processed_data.csv\")\n",
    "    summarized_df.to_csv(all_data_path, index=False)\n",
    "\n",
    "    trai_data_path = os.path.join(build_dir, \"data\", \"train_data.csv\")\n",
    "    train_df.to_csv(trai_data_path, index=False)\n",
    "\n",
    "    test_data_path = os.path.join(build_dir, \"data\", \"test_data.csv\")\n",
    "    test_df.to_csv(test_data_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "33cab0b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "build_dataset()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
